package io.surfworks.warpforge.core.endtoend;

import io.surfworks.snakeburger.stablehlo.StableHloAst;
import io.surfworks.snakeburger.stablehlo.StableHloParser;
import io.surfworks.warpforge.backend.cpu.CpuBackend;
import io.surfworks.warpforge.core.graph.ExecutableGraph;
import io.surfworks.warpforge.core.graph.GraphCompiler;
import io.surfworks.warpforge.core.graph.GraphExecutor;
import io.surfworks.warpforge.core.tensor.Tensor;
import io.surfworks.warpforge.core.testing.TensorAssert;
import io.surfworks.warpforge.core.testing.ToleranceConfig;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Tag;
import org.junit.jupiter.params.ParameterizedTest;
import org.junit.jupiter.params.provider.MethodSource;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.List;
import java.util.stream.Stream;

import static org.junit.jupiter.api.Assertions.assertArrayEquals;
import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.junit.jupiter.api.Assertions.fail;
import static org.junit.jupiter.api.Assumptions.assumeTrue;

/**
 * End-to-end tests comparing PyTorch execution results with WarpForge backend execution.
 *
 * <p>These tests:
 * <ol>
 *   <li>Load fixtures generated by snakegrinder --trace-with-values</li>
 *   <li>Parse the MLIR and compile to ExecutableGraph</li>
 *   <li>Execute on CpuBackend using GraphExecutor</li>
 *   <li>Compare outputs against PyTorch ground truth</li>
 * </ol>
 *
 * <p>Fixtures are located in: warpforge-core/src/test/resources/fixtures/e2e/
 *
 * <p>Test distribution:
 * <ul>
 *   <li>Quick fixtures (add, relu, softmax, etc.) - run on every CI push</li>
 *   <li>BERT fixtures (bert_squad_*) - run nightly only (tagged with "nightly")</li>
 * </ul>
 */
@Tag("cpu")
@DisplayName("PyTorch vs WarpForge E2E Tests")
class PyTorchWarpForgeEndToEndTest {

    /**
     * Fixtures are generated to build/ directory - NEVER committed to repo.
     * Run ./gradlew :warpforge-core:generateE2EFixtures to create them.
     */
    private static final Path FIXTURES_DIR = Paths.get(
        "build/generated-fixtures/e2e"
    );

    /**
     * Pattern for expensive fixtures that should only run nightly.
     * BERT models take significantly longer due to their size and complexity.
     */
    private static final java.util.regex.Pattern NIGHTLY_FIXTURE_PATTERN =
        java.util.regex.Pattern.compile("bert_.*");

    private CpuBackend backend;
    private GraphExecutor executor;

    @BeforeEach
    void setUp() {
        backend = new CpuBackend();
        executor = new GraphExecutor(backend);
    }

    @AfterEach
    void tearDown() {
        if (backend != null) {
            backend.close();
        }
    }

    /**
     * Discover quick E2E fixture directories (excludes BERT and other expensive fixtures).
     * These run on every CI push.
     */
    static Stream<Path> quickE2eFixtures() {
        return discoverFixtures(false);
    }

    /**
     * Discover expensive E2E fixture directories (BERT models).
     * These run nightly only.
     */
    static Stream<Path> nightlyE2eFixtures() {
        return discoverFixtures(true);
    }

    /**
     * Discover fixtures based on whether we want expensive (nightly) or quick fixtures.
     */
    private static Stream<Path> discoverFixtures(boolean nightlyOnly) {
        if (!Files.exists(FIXTURES_DIR)) {
            return Stream.of(Paths.get("NO_FIXTURES_AVAILABLE"));
        }

        try {
            List<Path> fixtures = Files.walk(FIXTURES_DIR)
                .filter(Files::isDirectory)
                .filter(dir -> Files.exists(dir.resolve("model.mlir")))
                .filter(dir -> Files.exists(dir.resolve("inputs")) || Files.exists(dir.resolve("outputs")))
                .filter(dir -> {
                    String name = dir.getFileName().toString();
                    boolean isExpensive = NIGHTLY_FIXTURE_PATTERN.matcher(name).matches();
                    return nightlyOnly ? isExpensive : !isExpensive;
                })
                .toList();

            if (fixtures.isEmpty()) {
                return Stream.of(Paths.get("NO_FIXTURES_AVAILABLE"));
            }
            return fixtures.stream();
        } catch (IOException e) {
            return Stream.of(Paths.get("NO_FIXTURES_AVAILABLE"));
        }
    }

    @ParameterizedTest(name = "{0}")
    @MethodSource("quickE2eFixtures")
    @DisplayName("PyTorch output matches WarpForge execution")
    void pytorchMatchesWarpforge(Path fixtureDir) throws IOException {
        runE2eTest(fixtureDir);
    }

    @ParameterizedTest(name = "{0}")
    @MethodSource("nightlyE2eFixtures")
    @Tag("nightly")
    @DisplayName("BERT model output matches WarpForge execution (nightly)")
    void bertMatchesWarpforge(Path fixtureDir) throws IOException {
        runE2eTest(fixtureDir);
    }

    private void runE2eTest(Path fixtureDir) throws IOException {
        // Skip if no fixtures are available
        if (fixtureDir.toString().equals("NO_FIXTURES_AVAILABLE")) {
            // Use assumeTrue to properly skip with visible message in JUnit report
            assumeTrue(false, "No EndToEnd fixtures found. Run: ./gradlew :warpforge-core:generateE2EFixtures");
            return;
        }

        try (EndToEndTestFixture fixture = EndToEndTestFixture.load(fixtureDir)) {
            // Skip if no outputs to compare
            if (fixture.expectedOutputs().isEmpty()) {
                System.out.println("Skipping " + fixture.name() + " - no expected outputs");
                return;
            }

            // Parse MLIR
            StableHloAst.Module module;
            try {
                module = StableHloParser.parse(fixture.mlir());
            } catch (Exception e) {
                fail("Failed to parse MLIR for " + fixture.name() + ": " + e.getMessage());
                return;
            }

            // Compile to ExecutableGraph
            ExecutableGraph graph;
            try {
                graph = GraphCompiler.compile(module);
            } catch (Exception e) {
                fail("Failed to compile graph for " + fixture.name() + ": " + e.getMessage());
                return;
            }

            // Verify input count matches (inputs + weights)
            assertEquals(fixture.totalArgCount(), graph.inputCount(),
                "Input count mismatch for " + fixture.name() +
                " (inputs=" + fixture.inputCount() + ", weights=" + fixture.weightCount() + ")");

            // Execute on CpuBackend with all inputs (inputs + weights)
            List<Tensor> actualOutputs;
            try {
                actualOutputs = executor.execute(graph, fixture.allInputs());
            } catch (UnsupportedOperationException e) {
                // Some operations may not be implemented yet
                System.out.println("Skipping " + fixture.name() + " - unsupported operation: " + e.getMessage());
                return;
            } catch (Exception e) {
                fail("Failed to execute graph for " + fixture.name() + ": " + e.getMessage());
                return;
            }

            // Compare output count
            assertEquals(fixture.outputCount(), actualOutputs.size(),
                "Output count mismatch for " + fixture.name());

            // Compare each output tensor
            for (int i = 0; i < actualOutputs.size(); i++) {
                Tensor expected = fixture.expectedOutputs().get(i);
                Tensor actual = actualOutputs.get(i);

                // Shape must match exactly
                assertArrayEquals(expected.shape(), actual.shape(),
                    "Output " + i + " shape mismatch for " + fixture.name());

                // Values must match within tolerance (use fixture name for operation-specific tolerance)
                ToleranceConfig tolerance = ToleranceConfig.forOp(fixture.name(), expected.dtype());
                try {
                    TensorAssert.assertEquals(expected, actual, tolerance);
                } catch (AssertionError e) {
                    fail("Output " + i + " value mismatch for " + fixture.name() + ": " + e.getMessage());
                }
            }

            // Clean up actual outputs (inputs and weights are owned by fixture)
            for (Tensor t : actualOutputs) {
                // Don't close if it's the same reference as input/weight (identity case)
                if (!fixture.allInputs().contains(t)) {
                    t.close();
                }
            }
        }
    }
}
