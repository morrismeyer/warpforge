name: Nightly Full Build

# Full clean build and comprehensive test suite
# Runs all unit tests, integration tests, and performance benchmarks
# with baseline validation to catch regressions

on:
  # Manual trigger for testing (enable this first to verify the workflow works)
  workflow_dispatch:
    inputs:
      rebuild_pytorch_venv:
        description: 'Rebuild PyTorch venv from scratch (adds ~60 min)'
        required: false
        default: true
        type: boolean
      skip_perf_tests:
        description: 'Skip performance tests (faster for debugging)'
        required: false
        default: false
        type: boolean
      skip_gpu_boxes:
        description: 'Skip GPU box tests (NUC only)'
        required: false
        default: false
        type: boolean

  # Nightly schedule - 2 AM EST (7 AM UTC) every day
  schedule:
    - cron: '0 7 * * *'

jobs:
  nightly-full-build:
    name: Full Build & Test Suite
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 180  # 3 hour max for full suite

    env:
      # Force all tests to actually run
      GRADLE_OPTS: '-Dorg.gradle.caching=false'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Pre-flight diagnostics
        run: |
          echo "=== Nightly Full Build Started ==="
          echo "Trigger: ${{ github.event_name }}"
          echo "Rebuild PyTorch venv: ${{ inputs.rebuild_pytorch_venv }}"
          echo "Skip perf tests: ${{ inputs.skip_perf_tests }}"
          echo "Skip GPU boxes: ${{ inputs.skip_gpu_boxes }}"
          echo "Runner: $(hostname)"
          echo "Date: $(date)"
          df -h
          free -h || true

      # ========================================
      # PHASE 1: Full Clean (Nuclear Option)
      # ========================================
      - name: Full repository clean
        run: |
          set -euo pipefail
          NUC_REPO="${HOME}/surfworks/warpforge"
          REBUILD_VENV="${{ inputs.rebuild_pytorch_venv }}"

          echo "=== Full Clean Phase ==="
          echo "Rebuild PyTorch venv: $REBUILD_VENV"

          if [[ -d "$NUC_REPO/.git" ]]; then
            cd "$NUC_REPO"
            git fetch origin
            git reset --hard "origin/${GITHUB_REF_NAME:-main}"

            # Determine what to clean
            if [[ "$REBUILD_VENV" == "true" ]]; then
              echo "NUCLEAR CLEAN: Removing EVERYTHING including PyTorch venv"
              echo "This verifies a new developer can build from scratch"
              git clean -fdx
              # Also remove any cached PyTorch source
              rm -rf snakegrinder-dist/.pytorch-venv
            else
              echo "Standard clean: Preserving PyTorch venv for speed"
              git clean -fdx -e '.pytorch-venv'
            fi

            # Explicitly remove Gradle caches
            rm -rf ~/.gradle/caches/build-cache-*
            rm -rf "$NUC_REPO/.gradle/build-cache"
            rm -rf "$NUC_REPO/.gradle"

            echo "Clean complete. Disk usage:"
            du -sh "$NUC_REPO" || true
            du -sh "$NUC_REPO/snakegrinder-dist/.pytorch-venv" 2>/dev/null || echo "No PyTorch venv"
          else
            echo "NUC repo not found, will be cloned"
            mkdir -p "$(dirname "$NUC_REPO")"
            git clone git@github.com:morrismeyer/warpforge.git "$NUC_REPO"
            cd "$NUC_REPO"
          fi

          echo "Git status after clean:"
          git status

      # ========================================
      # PHASE 1.5: Build PyTorch Venv (if needed)
      # ========================================
      - name: Build PyTorch venv from scratch
        if: ${{ inputs.rebuild_pytorch_venv }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== PyTorch Venv Build Phase ==="
          echo "This verifies that GraalPy + PyTorch builds correctly from source"
          echo "Expected duration: 30-60 minutes"

          # Check build dependencies
          echo "Checking build dependencies..."
          command -v cmake >/dev/null || { echo "ERROR: cmake not found"; exit 1; }
          command -v ninja >/dev/null || { echo "ERROR: ninja not found"; exit 1; }
          command -v g++ >/dev/null || { echo "ERROR: g++ not found"; exit 1; }

          echo "Dependencies OK. Starting PyTorch venv build..."
          START_TIME=$(date +%s)

          # Build the venv - this downloads GraalPy and builds PyTorch from source
          ./gradlew :snakegrinder-dist:buildPytorchVenv --no-build-cache --info 2>&1 | tee pytorch-venv-build.log

          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          echo "PyTorch venv build completed in $((DURATION / 60)) minutes $((DURATION % 60)) seconds"

          # Verify the venv was created
          VENV_DIR="snakegrinder-dist/.pytorch-venv"
          if [[ ! -d "$VENV_DIR" ]]; then
            echo "ERROR: PyTorch venv was not created at $VENV_DIR"
            exit 1
          fi

          echo "Verifying PyTorch import..."
          "$VENV_DIR/bin/graalpy" -c "import torch; print(f'PyTorch {torch.__version__} OK')"

          # Prune the venv to save space
          echo "Pruning venv to reduce size..."
          ./gradlew :snakegrinder-dist:prunePytorchVenv --no-build-cache

          echo "Final venv size:"
          du -sh "$VENV_DIR"

          echo "PyTorch venv build SUCCESS"

      # ========================================
      # PHASE 2: Full Build (No Cache)
      # ========================================
      - name: Full build - all modules
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== Full Build Phase (No Cache) ==="

          # Build everything from scratch
          ./gradlew clean assemble --no-build-cache --no-configuration-cache --info 2>&1 | tee build.log

          echo "Build complete. Checking artifacts..."
          find . -name "*.jar" -path "*/build/libs/*" | head -20

      # ========================================
      # PHASE 3: Unit Tests (NUC)
      # ========================================
      - name: Unit tests - all modules
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== Unit Tests Phase ==="

          # Run all unit tests without build cache
          ./gradlew test --no-build-cache --no-configuration-cache 2>&1 | tee test.log

          # Verify test counts
          echo "=== Test Result Summary ==="
          for module in snakeburger-core warpforge-core warpforge-io; do
            TEST_DIR="${module}/build/test-results/test"
            if [[ -d "$TEST_DIR" ]]; then
              COUNT=$(find "$TEST_DIR" -name "*.xml" -exec grep -h "tests=" {} \; | grep -oE 'tests="[0-9]+"' | grep -oE '[0-9]+' | awk '{sum+=$1} END {print sum}')
              echo "${module}: ${COUNT:-0} tests"
            fi
          done

      - name: Verify snakeburger-core tests
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          TEST_DIR="snakeburger-core/build/test-results/test"
          COUNT=$(find "$TEST_DIR" -name "*.xml" -exec grep -h "tests=" {} \; | grep -oE 'tests="[0-9]+"' | grep -oE '[0-9]+' | awk '{sum+=$1} END {print sum}')

          if [[ "${COUNT:-0}" -lt 300 ]]; then
            echo "ERROR: Expected at least 300 snakeburger-core tests, found ${COUNT:-0}"
            exit 1
          fi
          echo "SUCCESS: snakeburger-core tests passed (${COUNT} tests)"

      - name: Verify warpforge-core tests
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          TEST_DIR="warpforge-core/build/test-results/test"
          COUNT=$(find "$TEST_DIR" -name "*.xml" -exec grep -h "tests=" {} \; | grep -oE 'tests="[0-9]+"' | grep -oE '[0-9]+' | awk '{sum+=$1} END {print sum}')

          if [[ "${COUNT:-0}" -lt 100 ]]; then
            echo "ERROR: Expected at least 100 warpforge-core tests, found ${COUNT:-0}"
            exit 1
          fi
          echo "SUCCESS: warpforge-core tests passed (${COUNT} tests)"

      - name: Verify warpforge-io tests
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          TEST_DIR="warpforge-io/build/test-results/test"
          COUNT=$(find "$TEST_DIR" -name "*.xml" -exec grep -h "tests=" {} \; | grep -oE 'tests="[0-9]+"' | grep -oE '[0-9]+' | awk '{sum+=$1} END {print sum}')

          if [[ "${COUNT:-0}" -lt 150 ]]; then
            echo "ERROR: Expected at least 150 warpforge-io tests, found ${COUNT:-0}"
            exit 1
          fi
          echo "SUCCESS: warpforge-io tests passed (${COUNT} tests)"

      # ========================================
      # PHASE 4: SnakeGrinder Distribution & Packaging
      # ========================================
      - name: SnakeGrinder - test PyTorch venv
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== SnakeGrinder PyTorch Venv Tests ==="

          VENV_DIR="snakegrinder-dist/.pytorch-venv"
          if [[ ! -d "$VENV_DIR" ]]; then
            echo "ERROR: PyTorch venv not found at $VENV_DIR"
            echo "The venv should have been built in Phase 1.5"
            exit 1
          fi

          echo "Testing PyTorch venv..."
          ./gradlew :snakegrinder-dist:testPytorchVenv --no-build-cache --no-configuration-cache 2>&1 | tee snakegrinder-venv-test.log

          echo "PyTorch venv tests passed"

      - name: SnakeGrinder - build native image
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== SnakeGrinder Native Image Build ==="

          ./gradlew :snakegrinder-dist:buildNativeImage --no-build-cache --no-configuration-cache 2>&1 | tee snakegrinder-native-build.log || {
            echo "WARNING: SnakeGrinder native image build failed"
            echo "This may be expected if native-image is not fully configured"
          }

          NATIVE_EXE="snakegrinder-dist/build/native/nativeCompile/snakegrinder"
          if [[ -f "$NATIVE_EXE" ]]; then
            echo "SnakeGrinder native executable built: $(ls -lh "$NATIVE_EXE" | awk '{print $5}')"
          fi

      - name: SnakeGrinder - test native image
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== SnakeGrinder Native Image Tests ==="

          NATIVE_EXE="snakegrinder-dist/build/native/nativeCompile/snakegrinder"
          if [[ -f "$NATIVE_EXE" ]]; then
            ./gradlew :snakegrinder-dist:testNativeImage --no-build-cache --no-configuration-cache 2>&1 | tee snakegrinder-native-test.log
            echo "SnakeGrinder native image tests passed"
          else
            echo "WARNING: Native executable not found, skipping native image tests"
          fi

      - name: SnakeGrinder - assemble distribution
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== SnakeGrinder Distribution Assembly ==="

          ./gradlew :snakegrinder-dist:assembleDist --no-build-cache --no-configuration-cache 2>&1 | tee snakegrinder-assemble.log

          # Verify distribution was created
          DIST_DIR="snakegrinder-dist/build/dist"
          if [[ -d "$DIST_DIR" ]]; then
            echo "Distribution assembled:"
            ls -la "$DIST_DIR"
            echo "Total size: $(du -sh "$DIST_DIR" | cut -f1)"
          fi

      - name: SnakeGrinder - full distribution tests
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== SnakeGrinder Full Distribution Tests ==="

          ./gradlew :snakegrinder-dist:testDist --no-build-cache --no-configuration-cache 2>&1 | tee snakegrinder-dist-test.log

          echo "All SnakeGrinder distribution tests passed"

      # ========================================
      # PHASE 5: Native Image Build
      # ========================================
      - name: Build native-image UCC performance test
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== Native Image Build ==="

          # Build native-image for UCC performance tests
          ./gradlew :warpforge-io:nativeCompile --no-build-cache --no-configuration-cache 2>&1 | tee native-build.log || {
            echo "WARNING: Native image build failed (may be expected if GraalVM native-image not configured)"
            echo "Continuing without native tests..."
          }

          if [[ -f "warpforge-io/build/native/nativeCompile/ucc-perf-test" ]]; then
            echo "Native UCC perf test built successfully"
            ls -la warpforge-io/build/native/nativeCompile/
          fi

      # ========================================
      # PHASE 5.5: C Baseline Build
      # ========================================
      - name: Build C baseline on GPU boxes
        if: ${{ !inputs.skip_gpu_boxes }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== C Baseline Build ==="

          NVIDIA_HOST="${NVIDIA_HOST:-mark1nvidia}"
          AMD_HOST="${AMD_HOST:-mark1amd}"

          # Build C baseline on both GPU boxes
          echo "Building C baseline on NVIDIA box..."
          ssh -o ConnectTimeout=10 "$NVIDIA_HOST" "cd ~/projects/warpforge/holmes-lab/mark1/ucx-baseline && make clean && make ucc" || {
            echo "WARNING: C baseline build failed on NVIDIA"
          }

          echo "Building C baseline on AMD box..."
          ssh -o ConnectTimeout=10 "$AMD_HOST" "cd ~/projects/warpforge/holmes-lab/mark1/ucx-baseline && make clean && make ucc" || {
            echo "WARNING: C baseline build failed on AMD"
          }

          echo "C baseline build complete"

      # ========================================
      # PHASE 6: GPU Box Tests (NVIDIA + AMD)
      # ========================================
      - name: NVIDIA box - build and test
        if: ${{ !inputs.skip_gpu_boxes }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== NVIDIA Box Tests ==="

          # Use the existing orchestrator but with no-build-cache
          export TEST_CMD_OVERRIDE="./gradlew test --no-build-cache"
          export NVIDIA_TEST_CMD_OVERRIDE="./gradlew nvidiaTest --no-build-cache"

          chmod +x holmes-lab/mark1/ci-scripts/orchestrate-nvidia-build.sh
          bash holmes-lab/mark1/ci-scripts/orchestrate-nvidia-build.sh 2>&1 | tee nvidia-test.log

      - name: AMD box - build and test
        if: ${{ !inputs.skip_gpu_boxes }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== AMD Box Tests ==="

          # Use the existing orchestrator but with no-build-cache
          export TEST_CMD_OVERRIDE="./gradlew test --no-build-cache"
          export AMD_TEST_CMD_OVERRIDE="./gradlew amdTest --no-build-cache"

          chmod +x holmes-lab/mark1/ci-scripts/orchestrate-amd-build.sh
          bash holmes-lab/mark1/ci-scripts/orchestrate-amd-build.sh 2>&1 | tee amd-test.log

      # ========================================
      # PHASE 7: Two-Node Collective Performance Tests
      # ========================================
      # Runs all three implementations: C Baseline, Java JVM, Native-Image
      # Uses the head-to-head benchmark script for consistent comparison

      - name: Head-to-head performance benchmark (C, JVM, Native)
        if: ${{ !inputs.skip_perf_tests && !inputs.skip_gpu_boxes }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== Head-to-Head Performance Benchmark ==="
          echo "Testing all three implementations:"
          echo "  1. C Baseline (pure UCC)"
          echo "  2. Java JVM (FFM + UCC)"
          echo "  3. Native-Image (AOT compiled Java + FFM + UCC)"
          echo ""
          echo "Network: NVIDIA <-> AMD Mellanox 100GbE RDMA"

          # Create performance results directory
          PERF_RESULTS_DIR="$HOME/surfworks/warpforge/holmes-lab/mark1/results/nightly-$(date +%Y%m%d)"
          mkdir -p "$PERF_RESULTS_DIR"

          # Run the comprehensive head-to-head benchmark
          # --native flag includes all three: C baseline, Java JVM, and native-image
          chmod +x holmes-lab/mark1/ci-scripts/benchmark-head-to-head.sh
          ./holmes-lab/mark1/ci-scripts/benchmark-head-to-head.sh --native 2>&1 | tee "$PERF_RESULTS_DIR/head-to-head.log"

          echo ""
          echo "=== Extracting Performance Results ==="

          # Extract key metrics for each implementation
          echo "C Baseline Results:"
          grep -E "^(allreduce|broadcast|allgather|reduce_scatter|alltoall|barrier)" "$PERF_RESULTS_DIR/head-to-head.log" | head -6 || true

          echo ""
          echo "Java JVM Results:"
          grep "PERF_RESULT:" "$PERF_RESULTS_DIR/head-to-head.log" | head -6 || true

          echo ""
          echo "Native-Image Results:"
          grep "PERF_RESULT:" "$PERF_RESULTS_DIR/head-to-head.log" | tail -6 || true

          echo ""
          echo "Performance benchmark complete. Results saved to: $PERF_RESULTS_DIR/head-to-head.log"

      - name: Verify all benchmarks passed
        if: ${{ !inputs.skip_perf_tests && !inputs.skip_gpu_boxes }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          PERF_RESULTS_DIR="$HOME/surfworks/warpforge/holmes-lab/mark1/results/nightly-$(date +%Y%m%d)"
          LOG_FILE="$PERF_RESULTS_DIR/head-to-head.log"

          echo "=== Verifying Benchmark Results ==="

          # Check that all correctness tests passed
          PASS_COUNT=$(grep -c "Correctness:    PASS" "$LOG_FILE" 2>/dev/null || echo "0")
          FAIL_COUNT=$(grep -c "Correctness:    FAIL" "$LOG_FILE" 2>/dev/null || echo "0")

          echo "Correctness checks: $PASS_COUNT passed, $FAIL_COUNT failed"

          if [[ "$FAIL_COUNT" -gt 0 ]]; then
            echo "ERROR: Some correctness checks failed!"
            grep -B5 "Correctness:    FAIL" "$LOG_FILE" || true
            exit 1
          fi

          # Check that C baseline ran (should have lowercase collective names)
          if ! grep -q "^allreduce" "$LOG_FILE" 2>/dev/null; then
            echo "WARNING: C baseline results not found in log"
          else
            echo "C baseline: OK"
          fi

          # Check that Java JVM ran (should have PERF_RESULT lines with JVM warmup)
          JVM_RESULTS=$(grep -c "PERF_RESULT:" "$LOG_FILE" 2>/dev/null || echo "0")
          if [[ "$JVM_RESULTS" -lt 6 ]]; then
            echo "WARNING: Java results incomplete (expected at least 6, found $JVM_RESULTS)"
          else
            echo "Java JVM: OK ($JVM_RESULTS results)"
          fi

          # Check that native-image ran (look for native-specific output)
          if grep -q "Native-Image Java" "$LOG_FILE" 2>/dev/null; then
            echo "Native-Image: OK"
          else
            echo "WARNING: Native-image results not found"
          fi

          echo ""
          echo "Benchmark verification complete"

      # ========================================
      # PHASE 8: Performance Baseline Validation
      # ========================================
      - name: Validate performance against baselines
        if: ${{ !inputs.skip_perf_tests }}
        run: |
          set -euo pipefail
          cd ~/surfworks/warpforge

          echo "=== Performance Baseline Validation ==="

          BASELINE_DIR="holmes-lab/mark1/baselines"
          RESULTS_DIR="$HOME/surfworks/warpforge/holmes-lab/mark1/results/nightly-$(date +%Y%m%d)"

          if [[ ! -d "$BASELINE_DIR" ]]; then
            echo "No baseline directory found at $BASELINE_DIR"
            echo "Creating baseline directory for future runs..."
            mkdir -p "$BASELINE_DIR"
            echo "First run - no baseline comparison available"
            exit 0
          fi

          # TODO: Implement baseline comparison logic
          # - Parse performance results from logs
          # - Compare against stored baselines
          # - Fail if regression > threshold (e.g., 10%)
          # - Update baselines if improvement detected

          echo "Baseline validation complete (TODO: implement comparison logic)"

      # ========================================
      # Summary
      # ========================================
      - name: Test summary
        if: always()
        run: |
          echo "========================================"
          echo "       NIGHTLY FULL BUILD SUMMARY       "
          echo "========================================"
          echo "Completed at: $(date)"
          echo ""
          echo "=== Unit Test Results ==="
          cd ~/surfworks/warpforge

          for module in snakeburger-core warpforge-core warpforge-io snakeburger-codegen; do
            TEST_DIR="${module}/build/test-results/test"
            if [[ -d "$TEST_DIR" ]]; then
              TOTAL=$(find "$TEST_DIR" -name "*.xml" -exec grep -h "tests=" {} \; | grep -oE 'tests="[0-9]+"' | grep -oE '[0-9]+' | awk '{sum+=$1} END {print sum}')
              FAILED=$(find "$TEST_DIR" -name "*.xml" -exec grep -h "failures=" {} \; | grep -oE 'failures="[0-9]+"' | grep -oE '[0-9]+' | awk '{sum+=$1} END {print sum}')
              echo "  ${module}: ${TOTAL:-0} tests, ${FAILED:-0} failures"
            fi
          done

          echo ""
          echo "=== Performance Test Results ==="
          PERF_RESULTS_DIR="$HOME/surfworks/warpforge/holmes-lab/mark1/results/nightly-$(date +%Y%m%d)"
          if [[ -f "$PERF_RESULTS_DIR/head-to-head.log" ]]; then
            echo "Head-to-Head Benchmark (C vs JVM vs Native-Image):"
            echo ""
            echo "C Baseline:"
            grep -E "^(allreduce|broadcast|allgather|reduce_scatter|alltoall)" "$PERF_RESULTS_DIR/head-to-head.log" 2>/dev/null | head -5 || echo "  (not available)"
            echo ""
            echo "Java JVM (first 3 collectives):"
            grep "PERF_RESULT:" "$PERF_RESULTS_DIR/head-to-head.log" 2>/dev/null | head -3 || echo "  (not available)"
            echo ""
            PASS_COUNT=$(grep -c "Correctness:    PASS" "$PERF_RESULTS_DIR/head-to-head.log" 2>/dev/null || echo "0")
            FAIL_COUNT=$(grep -c "Correctness:    FAIL" "$PERF_RESULTS_DIR/head-to-head.log" 2>/dev/null || echo "0")
            echo "Correctness: $PASS_COUNT passed, $FAIL_COUNT failed"
          else
            echo "  Performance tests were skipped or not run"
          fi

          echo ""
          echo "========================================"
