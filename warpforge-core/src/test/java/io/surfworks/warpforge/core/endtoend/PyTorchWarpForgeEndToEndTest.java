package io.surfworks.warpforge.core.endtoend;

import io.surfworks.snakeburger.stablehlo.StableHloAst;
import io.surfworks.snakeburger.stablehlo.StableHloParser;
import io.surfworks.warpforge.backend.cpu.CpuBackend;
import io.surfworks.warpforge.core.graph.ExecutableGraph;
import io.surfworks.warpforge.core.graph.GraphCompiler;
import io.surfworks.warpforge.core.graph.GraphExecutor;
import io.surfworks.warpforge.core.tensor.Tensor;
import io.surfworks.warpforge.core.testing.TensorAssert;
import io.surfworks.warpforge.core.testing.ToleranceConfig;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Tag;
import org.junit.jupiter.params.ParameterizedTest;
import org.junit.jupiter.params.provider.MethodSource;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.List;
import java.util.stream.Stream;

import static org.junit.jupiter.api.Assertions.assertArrayEquals;
import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.junit.jupiter.api.Assertions.fail;

/**
 * End-to-end tests comparing PyTorch execution results with WarpForge backend execution.
 *
 * <p>These tests:
 * <ol>
 *   <li>Load fixtures generated by snakegrinder --trace-with-values</li>
 *   <li>Parse the MLIR and compile to ExecutableGraph</li>
 *   <li>Execute on CpuBackend using GraphExecutor</li>
 *   <li>Compare outputs against PyTorch ground truth</li>
 * </ol>
 *
 * <p>Fixtures are located in: warpforge-core/src/test/resources/fixtures/e2e/
 */
@Tag("cpu")
@DisplayName("PyTorch vs WarpForge E2E Tests")
class PyTorchWarpForgeEndToEndTest {

    private static final Path FIXTURES_DIR = Paths.get(
        "src/test/resources/fixtures/e2e"
    );

    private CpuBackend backend;
    private GraphExecutor executor;

    @BeforeEach
    void setUp() {
        backend = new CpuBackend();
        executor = new GraphExecutor(backend);
    }

    @AfterEach
    void tearDown() {
        if (backend != null) {
            backend.close();
        }
    }

    /**
     * Discover all E2E fixture directories.
     */
    static Stream<Path> e2eFixtures() {
        if (!Files.exists(FIXTURES_DIR)) {
            // Return a placeholder that will be skipped
            return Stream.of(Paths.get("NO_FIXTURES_AVAILABLE"));
        }

        try {
            List<Path> fixtures = Files.walk(FIXTURES_DIR)
                .filter(Files::isDirectory)
                .filter(dir -> Files.exists(dir.resolve("model.mlir")))
                .filter(dir -> Files.exists(dir.resolve("inputs")) || Files.exists(dir.resolve("outputs")))
                .toList();

            if (fixtures.isEmpty()) {
                return Stream.of(Paths.get("NO_FIXTURES_AVAILABLE"));
            }
            return fixtures.stream();
        } catch (IOException e) {
            return Stream.of(Paths.get("NO_FIXTURES_AVAILABLE"));
        }
    }

    @ParameterizedTest(name = "{0}")
    @MethodSource("e2eFixtures")
    @DisplayName("PyTorch output matches WarpForge execution")
    void pytorchMatchesWarpforge(Path fixtureDir) throws IOException {
        // Skip if no fixtures are available
        if (fixtureDir.toString().equals("NO_FIXTURES_AVAILABLE")) {
            System.out.println("No E2E fixtures found. Run: ./gradlew :warpforge-core:generateE2EFixtures");
            return;
        }

        try (EndToEndTestFixture fixture = EndToEndTestFixture.load(fixtureDir)) {
            // Skip if no outputs to compare
            if (fixture.expectedOutputs().isEmpty()) {
                System.out.println("Skipping " + fixture.name() + " - no expected outputs");
                return;
            }

            // Parse MLIR
            StableHloAst.Module module;
            try {
                module = StableHloParser.parse(fixture.mlir());
            } catch (Exception e) {
                fail("Failed to parse MLIR for " + fixture.name() + ": " + e.getMessage());
                return;
            }

            // Compile to ExecutableGraph
            ExecutableGraph graph;
            try {
                graph = GraphCompiler.compile(module);
            } catch (Exception e) {
                fail("Failed to compile graph for " + fixture.name() + ": " + e.getMessage());
                return;
            }

            // Verify input count matches (inputs + weights)
            assertEquals(fixture.totalArgCount(), graph.inputCount(),
                "Input count mismatch for " + fixture.name() +
                " (inputs=" + fixture.inputCount() + ", weights=" + fixture.weightCount() + ")");

            // Execute on CpuBackend with all inputs (inputs + weights)
            List<Tensor> actualOutputs;
            try {
                actualOutputs = executor.execute(graph, fixture.allInputs());
            } catch (UnsupportedOperationException e) {
                // Some operations may not be implemented yet
                System.out.println("Skipping " + fixture.name() + " - unsupported operation: " + e.getMessage());
                return;
            } catch (Exception e) {
                fail("Failed to execute graph for " + fixture.name() + ": " + e.getMessage());
                return;
            }

            // Compare output count
            assertEquals(fixture.outputCount(), actualOutputs.size(),
                "Output count mismatch for " + fixture.name());

            // Compare each output tensor
            for (int i = 0; i < actualOutputs.size(); i++) {
                Tensor expected = fixture.expectedOutputs().get(i);
                Tensor actual = actualOutputs.get(i);

                // Shape must match exactly
                assertArrayEquals(expected.shape(), actual.shape(),
                    "Output " + i + " shape mismatch for " + fixture.name());

                // Values must match within tolerance (use fixture name for operation-specific tolerance)
                ToleranceConfig tolerance = ToleranceConfig.forOp(fixture.name(), expected.dtype());
                try {
                    TensorAssert.assertEquals(expected, actual, tolerance);
                } catch (AssertionError e) {
                    fail("Output " + i + " value mismatch for " + fixture.name() + ": " + e.getMessage());
                }
            }

            // Clean up actual outputs (inputs and weights are owned by fixture)
            for (Tensor t : actualOutputs) {
                // Don't close if it's the same reference as input/weight (identity case)
                if (!fixture.allInputs().contains(t)) {
                    t.close();
                }
            }
        }
    }
}
