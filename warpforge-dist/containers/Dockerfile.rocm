# WarpForge ROCm Container
# AMD GPU-enabled image for ROCm workloads
#
# Build:
#   docker build -f Dockerfile.rocm -t warpforge:0.1.0-rocm ..
#
# Run (requires ROCm runtime and --device flags):
#   docker run --rm --device=/dev/kfd --device=/dev/dri warpforge:0.1.0-rocm gpu-info
#   docker run --rm --device=/dev/kfd --device=/dev/dri -v /data:/data warpforge:0.1.0-rocm submit --source /data/model.py

ARG WARPFORGE_VERSION=0.1.0
ARG ROCM_VERSION=6.0
ARG UBUNTU_VERSION=22.04

# Use ROCm base image
FROM rocm/dev-ubuntu-${UBUNTU_VERSION}:${ROCM_VERSION}

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    libgomp1 \
    libstdc++6 \
    libc6 \
    # RDMA support for multi-node training
    libibverbs1 \
    librdmacm1 \
    && rm -rf /var/lib/apt/lists/*

# Copy WarpForge distribution
ARG WARPFORGE_VERSION
COPY build/warpforge-${WARPFORGE_VERSION} /opt/warpforge

# Set up environment
ENV WARPFORGE_HOME=/opt/warpforge
ENV PATH="/opt/warpforge/bin:${PATH}"
ENV PYTORCH_VENV="/opt/warpforge/lib/python"

# ROCm environment
ENV ROCM_HOME=/opt/rocm
ENV HIP_PATH=${ROCM_HOME}
ENV LD_LIBRARY_PATH="${ROCM_HOME}/lib:${LD_LIBRARY_PATH}"

# UCX/UCC environment for collective operations
ENV UCX_TLS=rc,ud,sm,self

# Create non-root user (must be in video and render groups for GPU access)
RUN useradd -m -s /bin/bash -G video,render warpforge && \
    chown -R warpforge:warpforge /opt/warpforge

USER warpforge
WORKDIR /home/warpforge

# Default entrypoint
ENTRYPOINT ["/opt/warpforge/bin/warpforge"]
CMD ["--help"]

# Health check - verify GPU access
HEALTHCHECK --interval=60s --timeout=30s --start-period=10s --retries=3 \
    CMD ["/opt/warpforge/bin/warpforge", "gpu-info"]

# Labels
LABEL org.opencontainers.image.title="WarpForge ROCm"
LABEL org.opencontainers.image.description="WarpForge ML Compiler - AMD ROCm GPU image"
LABEL org.opencontainers.image.version="${WARPFORGE_VERSION}"
